{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "spec_morph_filter.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyOJy0pAeQEEgI+wu455YjTP",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/joeljose/audio_denoising/blob/main/spec_morph_filter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hQPeQwLCGY0"
   },
   "source": "# Noise Compensation using Spectrogram Morphological Filtering\n\nIn this project we apply image-based morphological filtering to audio spectrograms for removing noise. The core idea: a spectrogram is essentially a 2D image where bright regions represent high-energy signal content and dim regions represent noise. By treating it as an image, we can use classical image processing techniques — binary thresholding, erosion, and dilation — to separate signal from noise.\n\n**Erosion** (a minimum filter) shrinks bright regions, eliminating small isolated noise blobs. **Dilation** (a maximum filter) then expands the remaining regions back, restoring signal edges that were slightly eroded. The combination produces a binary mask that identifies where the signal lives. We use this mask to amplify signal regions and attenuate noise regions, creating a non-linear time-frequency filter. Finally, we reconstruct the denoised audio from the processed spectrogram using the inverse STFT."
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Pc5-vaRsIZj"
   },
   "source": "## Imports"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6xbPX_osPYyG"
   },
   "source": "from scipy.ndimage import binary_erosion\nfrom scipy.ndimage import binary_dilation\nimport scipy.signal as signal\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import Audio\nimport librosa",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GxGMfT6FrPd"
   },
   "source": "## Part 1: Synthetic Signal\n\nLet's first demonstrate the technique on a synthetic signal where we know the ground truth. We create 5 musical tones and add Gaussian noise."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HpDopRBDwg7x"
   },
   "source": "np.random.seed(42)\n\nfs=10000                                          # sampling frequency in Hz\nnotes=[837.31,1939.85,1054.94,1939.85,837.31]     # note frequencies in Hz\nnote_interval= 1                                  # duration of each note in seconds\nsong_time=len(notes)*note_interval                # Total duration of the song\n\n\ndt=1/fs\nt=np.arange(0,note_interval,dt)\n\ntones=[]\n\nfor fund_freq in notes:\n  tones.append(np.sin(2 * np.pi * fund_freq * t)) # each note is a sine wave \n\nsong = np.concatenate(tones)                      # add up all the notes to get our song",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kULSzZb7x3x"
   },
   "source": "Now let's add some noise to the song:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Q3BfRwIcGnCw"
   },
   "source": "# creating a noise with the same dimension as input signal \n\nmu, sigma = 0, 1                                  # mean and standard deviation of noise signal\nnoise = np.random.normal(mu, sigma, song.shape)  # generate noise signal using random function\n\nnoisy_song = song + noise                        # add the noise to the song to get noisy song",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOb0H6Ai6Veq"
   },
   "source": [
    "Let's hear the song"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s0aXyjZaIOIM"
   },
   "source": [
    "Audio(song, rate=fs)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb4pfODh6U28"
   },
   "source": [
    "Now let's hear the noisy signal "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HAgrtuVpN3yx"
   },
   "source": [
    "Audio(noisy_song, rate=fs)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOvBhht9sP0S"
   },
   "source": "### Helper Functions"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dmZf5a3b0rL1"
   },
   "source": "def draw_spectrogram(time, freq, magnitude, title, cmap='inferno'):\n  \"\"\"Plot a spectrogram from the magnitude of the STFT.\"\"\"\n  fig, ax = plt.subplots(figsize=(10, 5))\n  mesh = ax.pcolormesh(time, freq, magnitude, shading='gouraud',\n                       cmap=plt.get_cmap(cmap))\n  ax.set_ylim([freq[1], freq[-1]])\n  ax.set_title('Spectrogram of ' + title)\n  ax.set_ylabel('Frequency [Hz]')\n  ax.set_xlabel('Time [sec]')\n  fig.colorbar(mesh, ax=ax)\n\ndef draw_timeseries(input_signal, time):\n  \"\"\"Plot an audio signal waveform.\"\"\"\n  fig, ax = plt.subplots(figsize=(10, 5))\n  ax.plot(time, input_signal, color='c', linewidth=1.5, label=\"input\")\n  ax.set_xlim(time[0], time[-1])\n  ax.set_title('Signal')\n  ax.set_ylabel('Amplitude')\n  ax.set_xlabel('Time [sec]')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGBqtdT56m0x"
   },
   "source": "### Spectrograms\n\nWe create spectrograms by computing the Short-Time Fourier Transform (STFT) of the signal and plotting its magnitude. The STFT divides the signal into overlapping segments and computes the FFT of each, producing a time-frequency representation."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2y1qN9_EJZuM"
   },
   "source": [
    "nperseg = 512                                             # no. of samples in a segment\n",
    "\n",
    "freq, ti, Zxx = signal.stft(song, fs=fs, nperseg=nperseg) #STFT function\n",
    "\n",
    "draw_spectrogram(ti,freq,np.abs(Zxx),'song')              # we use our helper function to draw the spectrogram"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "M3NMJ3PoN-Ef"
   },
   "source": [
    "nperseg = 512\n",
    "\n",
    "freq, ti, Zxx = signal.stft(noisy_song, fs=fs, nperseg=nperseg)\n",
    "\n",
    "draw_spectrogram(ti,freq,np.abs(Zxx),'noisy song')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33MwiCbW60TM"
   },
   "source": "The magnitude of the complex-valued STFT (Zxx) gives us the spectrogram. Comparing the two, the original signal shows clean horizontal lines at each note's frequency, while the noisy version has energy scattered everywhere. The goal is to keep only the bright regions (high energy = signal) and suppress the dim regions (low energy = noise)."
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S18HG-PmDRYu"
   },
   "source": "### The Denoising Algorithm\n\nThe `morph_denoise` function takes the complex-valued STFT matrix (Zxx) and returns a denoised version (Rxx). The process has four steps:\n\n1. **Grayscale image**: Scale the STFT magnitude to 0–255, treating the spectrogram as a grayscale image.\n2. **Binary thresholding**: Pixels above the threshold are marked as signal (1), below as noise (0). The threshold controls how aggressive the separation is.\n3. **Morphological processing**: Erosion removes small isolated noise blobs by shrinking all white regions. Dilation then restores the signal regions that were slightly eroded. The result is a clean binary mask.\n4. **Masking**: Multiply signal regions (mask=1) by `amp` to boost them, and divide noise regions (mask=0) by `amp` to suppress them."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_ezXrSjqnxFn"
   },
   "source": "def morph_denoise(Zxx, threshold, amp, plot=True):\n  \"\"\"Apply morphological denoising to a complex-valued STFT matrix.\n\n  Parameters\n  ----------\n  Zxx : ndarray\n      Complex STFT matrix.\n  threshold : float\n      Binary threshold applied to the grayscale spectrogram (0-255).\n  amp : float\n      Amplification/attenuation factor for masked/unmasked regions.\n  plot : bool\n      If True, display intermediate processing images.\n\n  Returns\n  -------\n  Rxx : ndarray\n      Denoised complex STFT matrix.\n  \"\"\"\n  zmax = np.max(np.abs(Zxx))\n  gray_image = np.abs(Zxx) * (255 / zmax)\n\n  thresh_image = np.where(gray_image >= threshold, 1, 0)  # binary thresholding\n\n  mask_image = binary_erosion(thresh_image, iterations=1)\n  mask_image = binary_dilation(mask_image, iterations=2)\n\n  if plot:\n    fig, axis_arr = plt.subplots(1, 3, figsize=(15, 5))\n    axis_arr[0].set_title(\"grayscale spectrogram\")\n    axis_arr[0].imshow(gray_image, cmap=plt.cm.gray)\n    axis_arr[1].set_title(\"After binary thresholding\")\n    axis_arr[1].imshow(thresh_image, cmap=plt.cm.gray)\n    axis_arr[2].set_title(\"After Morphological filtering\")\n    axis_arr[2].imshow(mask_image, cmap=plt.cm.gray)\n    plt.tight_layout()\n\n  Rxx = np.where(mask_image == 1, Zxx * amp, Zxx / amp)\n\n  return Rxx",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNHRCPbHkgJV"
   },
   "source": [
    "Now let's apply the denoise function on Zxx to get Rxx."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y49ySITbezbs"
   },
   "source": "Rxx = morph_denoise(Zxx, threshold=40, amp=10)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJrSYWIybIEz"
   },
   "source": "The images above show the processing pipeline: the grayscale spectrogram, the binary thresholded image, and the final mask after morphological filtering. Small noise speckles are removed by erosion while the main signal bands are preserved and restored by dilation.\n\nThe images appear vertically flipped compared to the spectrograms because image row indices start from 0 at the top, but this does not affect the processing.\n\nLet's look at the recovered spectrogram:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ncYGjXUuff--"
   },
   "source": "draw_spectrogram(ti, freq, np.abs(Rxx), 'recovered song')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HULimF_HWwI8"
   },
   "source": "### Reconstruction\n\nNow let's reconstruct the audio signal from Rxx by applying the inverse STFT."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1kZuWpsLfcbD"
   },
   "source": [
    "_, xrec = signal.istft(Rxx, fs)\n",
    "\n",
    "Audio(xrec, rate=fs)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMQrZhXVxRR5"
   },
   "source": "## Part 2: Visual Mic Application\n\nThis technique was developed as part of the [Visual Mic](https://github.com/joeljose/Visual-Mic) project, which extracts audio from high-speed video of vibrating surfaces. The recovered audio signal is extremely noisy because the vibrations captured by the camera are tiny.\n\nThe signal has a native sample rate of only 2200 Hz (limited by the camera frame rate), meaning all signal content is below 1100 Hz. We process at this native rate so the STFT covers exactly 0–1100 Hz and the signal fills the entire spectrogram, giving the morphological operations a much better image to work with. We resample to 8000 Hz only for audio playback in the browser."
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "it2iV5_Z4RL-"
   },
   "source": "### Downloading the Audio"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ajTKWsBp86W8"
   },
   "source": "import os\nimport urllib.request\n\nwav_url = \"https://github.com/joeljose/assets/raw/master/audio_denoising/visualmic.wav\"\nwav_path = \"visualmic.wav\"\n\nif not os.path.exists(wav_path):\n    print(\"Downloading visualmic.wav ...\")\n    urllib.request.urlretrieve(wav_url, wav_path)\n    print(\"Done.\")\nelse:\n    print(\"visualmic.wav already exists, skipping download.\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1JzDUWw0Adz"
   },
   "source": "### Loading and Inspecting the Signal\n\nLet's load the audio file at its native sample rate, print its properties, and plot the waveform."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EnS7e2GclOTv"
   },
   "source": "noisy_signal, fs_wav = librosa.load(\"visualmic.wav\", sr=None)\n\nn = len(noisy_signal)\ndt = 1 / fs_wav\ntot_time = np.floor(n * dt)\nprint(f'Total playback time :{tot_time} seconds')\nprint(f'Total no. of samples :{n}')\nprint(f'Sampling frequency :{fs_wav} Hz')\n\n\nt = np.arange(0, tot_time, dt)\n\n# Plot the signal \n\ndraw_timeseries(noisy_signal, t)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dciND1G2KzO3"
   },
   "source": "Let's hear it. The native 2200 Hz rate is too low for browser playback, so we resample to 8000 Hz:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Q6NTnVVmK4Hv"
   },
   "source": "PLAYBACK_SR = 8000\nAudio(librosa.resample(noisy_signal, orig_sr=fs_wav, target_sr=PLAYBACK_SR), rate=PLAYBACK_SR)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxcgC057LDCi"
   },
   "source": "### Spectrogram\n\nSince we loaded at the native 2200 Hz sample rate, the STFT covers 0–1100 Hz and the signal fills the entire spectrogram."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cOmWfHsqKR18"
   },
   "source": "nperseg = 512\n\nfreq, ti, Zxx = signal.stft(noisy_signal, fs=fs_wav, nperseg=nperseg)\n\ndraw_spectrogram(ti, freq, np.abs(Zxx), 'noisy signal obtained from visual mic')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVUGU7FWLVt5"
   },
   "source": "### Applying Morphological Denoising\n\nWith the signal filling the full spectrogram, the morphological operations can effectively distinguish signal from noise."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-Nv5StCULVt7"
   },
   "source": "Rxx = morph_denoise(Zxx, threshold=20, amp=10)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEJmknOdLmRw"
   },
   "source": "### Recovered Spectrogram"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s8jR9qp1LmR2"
   },
   "source": "draw_spectrogram(ti, freq, np.abs(Rxx), 'recovered signal from visual mic')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2o_G_xj9LmR6"
   },
   "source": "### Reconstruction\n\nLet's reconstruct the denoised audio using the inverse STFT and resample for playback."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZvuzM-CWLmR-"
   },
   "source": "_, xrec = signal.istft(Rxx, fs_wav)\nAudio(librosa.resample(xrec, orig_sr=fs_wav, target_sr=PLAYBACK_SR), rate=PLAYBACK_SR)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWwE3GNl3jRP"
   },
   "source": "The reconstructed audio is a much clearer version of \"Mary Had a Little Lamb.\""
  }
 ]
}